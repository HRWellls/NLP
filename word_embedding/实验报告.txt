Word Embeddingѧ3220100975뿭1. Project Introduction1 ѡʵǡȻԴеһԽģѧϰͬͳƣͼѰһӲͬȻԵʵʵӳ䡣2 WikipediaϣڻΪModelArtsƽ̨ʹGensimѵWord2Vecģͣɴʵ¹ܣI.ѵͨSkip-gramCBOWģѧϰеĴʻֲII.֤ѵõĴĿ﷨Ĵʻ㡣3 ϵͳI.	   Jupyter NotebookII.	   Python 3.7III.Ŀ	   GensimIV. 	ModelArts Ascend V.ݼ	   Wikipediaϣcorpus.txt2. Technical Details1 ֪ʶI.ͨȻеĵӳ䵽άʵռ䣬׽ʻ﷨ϵӶΪıࡢзȣṩЧʾII.Word2Vecԭ    - Skip-gramģ:ͨĴԤĴʣĴʵ    - CBOWģ:ͨĴԤĴʣŻĴʵ    III.ͨŻѵЧʣͳSoftmax㡣        2 㷨I.Ԥ    -Ԥȥͣôʣ    -ıתΪII.ģѵ    -ʼWord2Vecģͣó    -ͨǳѧϰIII    -ļembedding.txtʽΪ ֵ3 ϸڣؼ⣩I. gensim.models.Word2VecGensimṩģ֧࣬Skip-gram/CBOWѵII. KeyedVectors.load_word2vec_formatԤѵļ֧ƶȼ㡣III. most_similar(word):ѵõģͣҵ뵱ǰwordļʡкľ彫ںи3. Experiment Results1.Jupyter notebookϴݣѵdatanotebookļ2.ѡΪmindquantumںˣpython3.װgensimֶϴݣԲҪnotebookmoxͬݵĲ֡4.·5.鿴ĵ6ѵѵmodel = Word2Vec(corpus_file=corpus_file, vector_size=100, window=5, min_count=5, workers=cpu_count(), sg=1)# ͳ# corpus_fileϿļ·# vector_sizeά# windowĴڴС# min_countСƵ# workersʹõ߳# sgʹSkip-gramģͣ1CBOWģͣ0model.wv.save_word2vec_format(out_embedding_file, binary=False)Կword2vecһѡģͣԽʵ鱨ҽֱֳ֣չʾSkip-gramģͺCBOWģ͸ԵĽSkip-gramģͣԿڸģ£ѵģͶɶеʵѵȳ100%Ŀ¼Ҳ˴ѵembedding.txtļCBOWģͣsgֵΪ0model = Word2Vec(corpus_file=corpus_file, vector_size=100, window=5, min_count=5, workers=cpu_count(), sg=0)# ͳ# corpus_file: ļ·# vector_size: ά# window: ĴڴС# min_count: ԵڸƵʵĵ# workers: ʹõ߳# sg: 0ʾCBOWģͣ1ʾSkip-gramģmodel.wv.save_word2vec_format(out_embedding_file, binary=False)ԿģҲܹɶѵ7.ߴSkip-gramģͣԿÿʶӳΪһ100άCBOWģͣͬʵ˳ɹѧϰǽһģȫͬ   8.ƶȲԣ룺testwords = ['', 'ϲ', "й", ""]for word in testwords:  res = word2vec_model.most_similar(word) # wordƵǰ10  print (word)  print (res)Skip-gramģͽԿͨѧϰڷ񡱡ŴȴʱΪ롰ڡһΪأǵĻʶһ£˵ʵɹCBOWģͽԿһģͬCBOWѷһȻԤڡ