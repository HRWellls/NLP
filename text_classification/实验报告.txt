Project Name学号姓名3220100975汪珉凯1. Project Introduction（1） 选题本次实验选题为基于TextCNN的文本情感分类，属于自然语言处理（NLP）中的经典任务。实验通过构建卷积神经网络（CNN）模型，对电影评论进行情感倾向分析（正面或负面），适用于垃圾评论过滤、产品评价分析等实际场景。（2） 工作简介目标：实现一个能自动判断电影评论情感倾向（正面/负面）的模型。流程：数据预处理→构建TextCNN模型→训练与评估→部署测试。输入：原始英文评论文本。输出：情感分类结果（0/1）。（3） 开发环境及系统运行要求开发工具： 华为云ModelArts Ascend Notebook（基于JupyterLab）。开发包与库：深度学习框架：MindSpore 1.1依赖库：NumPy、Pandas、os、random等Python标准库。硬件要求： 华为?腾Ascend环境。2. Technical Details（1） 理论知识阐述文本分类流程：文本向量化：通过词嵌入将单词映射为稠密向量。特征提取：使用CNN捕捉局部语义特征。分类输出：全连接层输出类别概率。CNN在文本中的应用：卷积核滑动窗口提取局部特征。池化层保留显著特征，降低维度。（2） TextCNN模型结构：Input → Embedding → [Conv1D + ReLU + MaxPool]×3 → Concatenate → FC → Output  （3） 重要技术细节核心库与函数：mindspore.nn.Conv2d：实现二维卷积（需扩展输入维度适配文本）。mindspore.nn.Embedding：词嵌入层，将单词索引映射为向量。ops.ReduceMax：沿指定维度取最大值（替代全局池化）。自定义功能：MovieReview类：封装数据读取、清洗、分割逻辑。preprocess()函数：文本预处理（特殊符号过滤、词典匹配）。（4） 流程：输入文本 → [单词索引] → Embedding层 → 多尺寸卷积 → 最大池化 → 拼接 → 全连接 → Softmax  3. Experiment Results1. 上传notebook和实验数据2. 导入依赖库这里导入了数学计算库（math、numpy、pandas）、系统工具（os、pathlib、random、codecs）以及MindSpore深度学习框架的核心组件（数据加载、模型构建、训练控制、评估指标和底层算子），用于实现从数据处理到模型训练评估的完整深度学习流程。3. 设置超参数这段代码通过EasyDict定义了一个电影评论情感分类任务的配置参数，其中包含模型训练的关键超参数：任务名称设为'movie review'，使用二分类模型（num_classes=2），设置批量大小为64（batch_size），训练轮次为4（epoch_size），并加入L2正则化（weight_decay=3e-5）以防止过拟合。数据存储路径为'./data/'，模型运行在华为Ascend芯片（device_target='Ascend'）的0号设备上（device_id=0）。输入文本被统一处理为最大51词长度（word_len），词向量维度设为40（vec_length），同时配置检查点保存策略（keep_checkpoint_max=1）指定只保留最新模型。4. 设置运行环境context.set_context将MindSpore设置为静态图模式以优化计算性能。5. 数据预处理（分为以下两个部分）：5.1数据查看：打开了两个文件（负面评论rt-polarity.neg和正面评论rt-polarity.pos），分别打印了前5条评论。5.2基本格式展示：每条评论前面加上了索引编号（[0], [1]等），方便查看。		5.3正式处理	主要功能包括从指定目录加载正面和负面评论文件，对文本进行清洗（去除标点、数字和特殊字符），统计句子长度信息，构建词汇表并将单词转换为整数索引，通过截断或填充将句子统一为固定长度，按比例划分训练集和测试集，并最终生成适合MindSpore框架使用的数据生成器，输出整数序列形式的评论数据和对应的情感标签（0或1），为后续的情感分类模型训练提供结构化输入。部分代码如下：    5.4数据信息可视化    设置具体路径，然后获取数据集的词汇表大小并打印，然后通过数据集的迭代器读取第一批数据，打印出数据的结构和其中一条评论的向量化内容，用于快速检查数据预处理后的格式是否正确。        6训练模型    	6.1设定训练参数    	学习率采用动态调整的策略，先通过线性增长进行warm-up预热，然后保持恒定学习率稳定训练，最后采用逐步衰减的方式精细调参，从而优化模型训练过程。	6.2核心部分：文本分类模型实现实现一个基于TextCNN的文本分类模型，通过嵌入层将单词索引转换为词向量后，使用三种不同高度的卷积核（3、4、5）并行提取文本特征，经ReLU激活和最大池化后拼接各通道结果，最后通过全连接层和Dropout输出分类预测。部分代码如下：变量解释：vocab_len表示词汇表的大小，决定了嵌入层的输入维度；word_len指定了输入文本序列的最大长度，用于控制卷积和池化操作的范围；num_classes是分类任务的类别数量，直接影响输出层的维度；vec_length设定词向量的维度大小，影响嵌入层的输出特征空间。模型内部使用self.embedding将单词索引映射为稠密向量，通过三个不同高度（3、4、5）的卷积层layer1/layer2/layer3并行提取文本特征，其中每个卷积层输出96个通道的特征图，最终通过concat拼接各层特征后，经全连接层fc（输入维度96*3，输出维度num_classes）和Dropout层（保留概率0.5）完成分类预测，而reducemean用于对特征图进行全局最大池化降维。	6.3定义其他部分（包括优化器和损失函数等）   6.4正式训练可以看到，随着训练论述的上升，损失值不断下降。7.测试评估可以看到准确率在74%左右。8.在线测试给出特定的评论，查看模型是否能够正确判断情感倾向：后面我又加入了不同类型的评论，如下所示：可以看到模型都能够正确判断评价的情感类型。